input {
    # read files from standard in.
    # On Linux we can cat somefile | logstash
    # On Windows, type somefile | logstash
    stdin {
        type => "api"
    }
}

filter {
    # don't read the csv file header
    if [message] !~ /^\d+/ {
        drop {
        }
    }
    # assign names to the csv columns/fields
    csv {
        columns => ["date","average_api","max_api","min_api","station_name","station_type","latitude","longitude"]
        remove_field => ["message"]
    }
    # create a location field from the latitude and longitude fields
    mutate {
        add_field => { "location" => "%{latitude},%{longitude}" }
    }
    # properly assign a date to the record
    date {
        match => ["date", "YYYY-MM-dd", "YYYY/MM/dd", "dd-MM-YYYY", "dd/MM/YYYY"]
        remove_field => "date"
    }
}

output {
    # index into Elasticsearch
    elasticsearch {
        index => "hk-api"
        template => "api-elasticsearch-template.json"
        template_name => "hk-api"
    }
    # print out a dot for each line processed
    stdout {
        codec => "dots"
    }
}
